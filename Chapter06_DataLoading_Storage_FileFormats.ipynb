{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter06_DataLoading_Storage_FileFormats.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyentranforte1609/Book_PythonForDataAnalysis/blob/master/Chapter06_DataLoading_Storage_FileFormats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oK55jpIh59u",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 06: Data Loading, Storage, and File Formats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iek8aO-R8zmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "example06DataURL = 'https://raw.githubusercontent.com/wesm/pydata-book/2nd-edition/examples/ex6.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blsLptGsiJIO",
        "colab_type": "text"
      },
      "source": [
        "## 6.1 Reading and Writing Data in Text Format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAkyus7y82Ik",
        "colab_type": "text"
      },
      "source": [
        "- Parsing functions in pandas\n",
        "\n",
        "| Function | Description |\n",
        "|----------|-------------|\n",
        "| read_csv | Load delimited data from a file, URL, or file-like  object; use comma as default delimiter |\n",
        "| read_table | Load delimited data from a file, URL, or file-like object; use tab ('\\t') as default delimiter |\n",
        "| read_fwf | Read data in fixed-width column format |\n",
        "| read_clipboard | Version of `read_table` that reads data from the clipboard; useful for converting tables from web pages |\n",
        "| read_excel | Read tabular data from an Excel XLS or XLSX file |\n",
        "| read_hdf | Read HDF5 files written by pandas |\n",
        "| read_html | Read all tables found in the given HTML document |\n",
        "| read_json | Read data from a JSON string representation |\n",
        "| read_msgpack | Read pandas data encoded using the MessagePack binary format |\n",
        "| read_pickle | Read an arbitrary object stored in Python pickle format |\n",
        "| read_sas | Read a SAS dataset stored in one of the SAS system's custom storrage formats |\n",
        "| read_sql | Read the result of a SQL query as a pandas DataFrame |\n",
        "| read_stata | Read a dataset from Stata file format |\n",
        "| read_feather | Read the Feather binary file format |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PekotER1GnKV",
        "colab_type": "text"
      },
      "source": [
        "- Some `read_csv`/`read_table` function arguments\n",
        "\n",
        "| Argument | Description |\n",
        "|----------|-------------|\n",
        "| path | String indicating filesystem location, URL, or file-like object |\n",
        "| sep or delimiter | Character sequence or regular expression to use to split fields in each row |\n",
        "| header | Row number to use as column names; defaults to 0 (first row), but should be None if there is no header row |\n",
        "| index_col | Column numbers or names to use as the row index in the result, can be a single name/ number or a list of them for a hierachical index |\n",
        "| names | List of column names for result, combine with header=None |\n",
        "| skiprows | Number of rows at beginning of file to ignore or list of row numbers (starting from 0) to skip |\n",
        "| na_values | Sequence of values to replace with NA |\n",
        "| comment | Character(s) to split comments off the end of lines |\n",
        "| parse_dates | Attempt to parse data to `datetime`; `False` by default. If `True`, will attempt to parse all columns. Otherwise can specify a list of column numbers or name to parse. If element of list is tuple or list, will combine multiple columns together and parse to `date`|\n",
        "| keep_date_col | If joining colums to parse data, keep the joined columns; `False` by default |\n",
        "| converters | Dict containing column number of name mapping to functions |\n",
        "| dayfirst | When parsing potentially ambiguous dates, treat as international format; `False` by default |\n",
        "| date_parser | Function to use to parse dates |\n",
        "| nrows | Number of rows to read from the beginning of file |\n",
        "| iterator | Return a TextParser object for reading file piecemeal |\n",
        "| chunksize | Size of file chunks for each iteration |\n",
        "| skip_footer | Number of lines to ignore at end of file |\n",
        "| verbose | Print various parser output information, like the number of missing values placed in non-numeric columns |\n",
        "| encoding | Text encoding for Unicode |\n",
        "| squeeze | If the parsed data only contains one column, return a Series |\n",
        "| thousans | Separator for thousands |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw850xbvKOtY",
        "colab_type": "text"
      },
      "source": [
        "### Reading Files in Pieces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfd6q5FkNHMk",
        "colab_type": "text"
      },
      "source": [
        "- When processing very large files or figuring out the right set of arguments to correctly process a large file, we may want to read in a small piece of a file or iterate through smaller chunks of the file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrwVhhxuNWP6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "50480f3c-00ce-438f-bee6-9b35616326f0"
      },
      "source": [
        "# Example - Reading the first 5 rows of a large CSV file\n",
        "ex06Data = pd.read_csv(example06DataURL, nrows = 5)\n",
        "ex06Data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>one</th>\n",
              "      <th>two</th>\n",
              "      <th>three</th>\n",
              "      <th>four</th>\n",
              "      <th>key</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.467976</td>\n",
              "      <td>-0.038649</td>\n",
              "      <td>-0.295344</td>\n",
              "      <td>-1.824726</td>\n",
              "      <td>L</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.358893</td>\n",
              "      <td>1.404453</td>\n",
              "      <td>0.704965</td>\n",
              "      <td>-0.200638</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.501840</td>\n",
              "      <td>0.659254</td>\n",
              "      <td>-0.421691</td>\n",
              "      <td>-0.057688</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.204886</td>\n",
              "      <td>1.074134</td>\n",
              "      <td>1.388361</td>\n",
              "      <td>-0.982404</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.354628</td>\n",
              "      <td>-0.133116</td>\n",
              "      <td>0.283763</td>\n",
              "      <td>-0.837063</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        one       two     three      four key\n",
              "0  0.467976 -0.038649 -0.295344 -1.824726   L\n",
              "1 -0.358893  1.404453  0.704965 -0.200638   B\n",
              "2 -0.501840  0.659254 -0.421691 -0.057688   G\n",
              "3  0.204886  1.074134  1.388361 -0.982404   R\n",
              "4  0.354628 -0.133116  0.283763 -0.837063   Q"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeeGPlQfOK6C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "ef0a8df9-36a0-4117-9efb-70480a7b0404"
      },
      "source": [
        "# Example -Reading a chunk of data from a large CSV file\n",
        "# then iterate through row data in chunk and count values\n",
        "ex06DataChunk = pd.read_csv(example06DataURL, chunksize = 1000)\n",
        "\n",
        "countResult = pd.Series([])\n",
        "for row in ex06DataChunk:\n",
        "    countResult = countResult.add(row['key'].value_counts(), fill_value=0)\n",
        "\n",
        "countResult[:5]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    151.0\n",
              "1    146.0\n",
              "2    152.0\n",
              "3    162.0\n",
              "4    171.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0wIgmD6fSiX",
        "colab_type": "text"
      },
      "source": [
        "## The rest of this chapter is Skipped"
      ]
    }
  ]
}